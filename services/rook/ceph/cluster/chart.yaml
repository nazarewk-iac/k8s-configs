# HelmChartInflationGenerator docs are wrong, see https://github.com/kubernetes-sigs/kustomize/blob/b0d7721049d557063e324c7c2c1ef45bb73e4bdc/api/types/helmchartargs.go#L33-L75
apiVersion: builtin
kind: HelmChartInflationGenerator
metadata:
  name: rook-ceph-cluster

name: rook-ceph-cluster
repo: https://charts.rook.io/release
version: v1.8.8

releaseName: rook-ceph-cluster
namespace: rook-ceph

valuesInline:
  toolbox:
    enabled: true

  clusterName: rook-ceph-nazarewk-krul
  cephClusterSpec:
    dataDirHostPath: /var/lib/rook/rook-ceph-nazarewk-krul

    # see https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/#marking-pod-as-critical
    priorityClassNames:
      all: system-node-critical

    mon:
      count: 3
      allowMultiplePerNode: true  # running single node for now

    storage:
      useAllNodes: true
      useAllDevices: false
      storageClassDeviceSets:
        - name: rook-ceph-nvme
          count: 1
          portable: false
          encrypted: true
          config:
            deviceClass: nvme
          volumeClaimTemplates:
            # for whatever reason I need to manually change class from ssd to nvme using:
            # 1. `ceph osd crush rm-device-class OSD_NO`
            # 2. `ceph osd crush set-device-class nvme OSD_NO`
            - metadata:
                labels:
                  storage.nazarewk.pw/device-class: nvme

              spec:
                storageClassName: manual-rook-ceph-cluster
                resources:
                  requests:
                    storage: 1020G
                volumeMode: Block
                accessModes:
                  - ReadWriteOnce
        - name: rook-ceph-ssd
          count: 2
          portable: false
          encrypted: true
          config:
            deviceClass: ssd
          volumeClaimTemplates:
            - metadata:
                labels:
                  storage.nazarewk.pw/device-class: ssd
              spec:
                storageClassName: manual-rook-ceph-cluster
                resources:
                  requests:
                    storage: 2040G
                volumeMode: Block
                accessModes:
                  - ReadWriteOnce
        - name: rook-ceph-hdd
          count: 2
          portable: false
          encrypted: true
          config:
            deviceClass: hdd
          volumeClaimTemplates:
            - metadata:
                labels:
                  storage.nazarewk.pw/device-class: hdd

              spec:
                storageClassName: manual-rook-ceph-cluster
                resources:
                  requests:
                    storage: 4040G
                volumeMode: Block
                accessModes:
                  - ReadWriteOnce

    resources:
      mon:
        limits:
          # mon seems to be single-threaded
          cpu: 1
          memory: 4Gi
    healthCheck:
      daemonHealth:
        mon:
          disabled: false
          interval: 1m
          timeout: 15m
      livenessProbe:
        mon:
          disabled: false
          probe: &livenessProbe
            timeoutSeconds: &timeout 120
            periodSeconds: &period 29
            failureThreshold: &livenessFailure 4
        mgr:
          disabled: false
        osd:
          disabled: false
      startupProbe:
        mon:
          disabled: false
          probe: &startupProbe
            periodSeconds: *period
            timeoutSeconds: 5
            initialDelaySeconds: 10
            failureThreshold: 240
        mgr:
          disabled: false
          probe: *startupProbe
        osd:
          disabled: false
          probe: *startupProbe

  monitoring:
    enabled: true

  cephBlockPools:
    - name: ssd-2-replicas
      spec:
        deviceClass: ssd
        failureDomain: osd
        replicated:
          size: 2
      storageClass:
        name: block-ssd-2-replicas
        enabled: true
        isDefault: false
        allowVolumeExpansion: true
        reclaimPolicy: Delete
        parameters: &storage-class-parameters
          # (optional) mapOptions is a comma-separated list of map options.
          # For krbd options refer
          # https://docs.ceph.com/docs/master/man/8/rbd/#kernel-rbd-krbd-options
          # For nbd options refer
          # https://docs.ceph.com/docs/master/man/8/rbd-nbd/#options
          # mapOptions: lock_on_read,queue_depth=1024

          # (optional) unmapOptions is a comma-separated list of unmap options.
          # For krbd options refer
          # https://docs.ceph.com/docs/master/man/8/rbd/#kernel-rbd-krbd-options
          # For nbd options refer
          # https://docs.ceph.com/docs/master/man/8/rbd-nbd/#options
          # unmapOptions: force

          # RBD image format. Defaults to "2".
          imageFormat: "2"
          # RBD image features. Available for imageFormat: "2". CSI RBD currently supports only `layering` feature.
          imageFeatures: layering
          # The secrets contain Ceph admin credentials.
          # WARNING: below 2 are required for provisioning PVCs
          csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
          csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
          # WARNING: below 2 are required for resizing PVCs
          csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
          csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
          # WARNING: below 2 are required for... don't know what?
          csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
          csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
          # Specify the filesystem type of the volume. If not specified, csi-provisioner
          # will set default as `ext4`. Note that `xfs` is not recommended due to potential deadlock
          # in hyperconverged settings where the volume is mounted on the same node as the osds.
          csi.storage.k8s.io/fstype: ext4

    - name: hdd-2-replicas
      spec:
        deviceClass: hdd
        failureDomain: osd
        replicated:
          size: 2
      storageClass:
        name: block-hdd-2-replicas
        enabled: true
        isDefault: false
        allowVolumeExpansion: true
        reclaimPolicy: Delete
        parameters: *storage-class-parameters

    - name: fast-2-replicas
      spec:
        failureDomain: osd
        replicated:
          size: 2
          hybridStorage:
            primaryDeviceClass: nvme
            secondaryDeviceClass: ssd
      storageClass:
        name: block-fast-2-replicas
        enabled: true
        isDefault: false
        allowVolumeExpansion: true
        reclaimPolicy: Delete
        parameters: *storage-class-parameters

    - name: fast-3-replicas
      spec:
        failureDomain: osd
        replicated:
          size: 3
          hybridStorage:
            primaryDeviceClass: nvme
            secondaryDeviceClass: ssd
      storageClass:
        name: block-fast-3-replicas
        enabled: true
        isDefault: false
        allowVolumeExpansion: true
        reclaimPolicy: Delete
        parameters: *storage-class-parameters

    - name: medium-2-replicas
      spec:
        failureDomain: osd
        replicated:
          size: 2
          hybridStorage:
            primaryDeviceClass: ssd
            secondaryDeviceClass: hdd
      storageClass:
        name: block-medium-2-replicas
        enabled: true
        isDefault: false
        allowVolumeExpansion: true
        reclaimPolicy: Delete
        parameters: *storage-class-parameters

    - name: medium-3-replicas
      spec:
        failureDomain: osd
        replicated:
          size: 3
          hybridStorage:
            primaryDeviceClass: ssd
            secondaryDeviceClass: hdd
      storageClass:
        name: block-medium-3-replicas
        enabled: true
        isDefault: false
        allowVolumeExpansion: true
        reclaimPolicy: Delete
        parameters: *storage-class-parameters

  #    - name: medium-4-replicas
  #      spec:
  #        failureDomain: osd
  #        replicated:
  #          size: 4
  #          hybridStorage:
  #            primaryDeviceClass: ssd
  #            secondaryDeviceClass: hdd
  #      storageClass:
  #        name: medium-4-replicas
  #        enabled: true
  #        isDefault: false
  #        allowVolumeExpansion: true
  #        reclaimPolicy: Delete
  #        parameters: *storage-class-parameters

  cephFileSystems: []
  cephObjectStores: []
